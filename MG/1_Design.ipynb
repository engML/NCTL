{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDTVl-o_5hLF",
        "outputId": "432d5cac-7be3-42b9-c861-04a00c188d55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "# import modules\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import kerastuner as kt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "rnd_seed = 1\n",
        "tf.random.set_seed(rnd_seed)\n",
        "np.random.seed(rnd_seed)\n",
        "\n",
        "hyperbandit = True  # Bayesian optimization if false\n",
        "\n",
        "dir_opt = 'ANN Structure Design'\n",
        "if not os.path.exists(dir_opt): os.makedirs(dir_opt)\n",
        "dir_prj = 'Hyperband Optimization' if hyperbandit else 'Bayesian Optimization'\n",
        "output_folder = 'Metamodel Hyperband' if hyperbandit else 'Metamodel Bayesian'\n",
        "output_dir = os.path.join(dir_opt,dir_prj,output_folder)\n",
        "if not os.path.exists(output_dir): os.makedirs(output_dir)\n",
        "log_dir = os.path.join(output_dir,'ANN_info.txt')\n",
        "#sys.stdout = open(log_dir, \"w\")\n",
        "\n",
        "# load input data\n",
        "data_folder = 'Datasets'\n",
        "file_train = 'Nu_train_1.csv'\n",
        "file_test = 'Nu_test.csv'\n",
        "\n",
        "dir_train = os.path.join(data_folder, file_train)\n",
        "dir_test = os.path.join(data_folder, file_test)\n",
        "\n",
        "dataframe_train = pd.read_csv(dir_train, delim_whitespace=True, header=None)\n",
        "dataframe_test = pd.read_csv(dir_test, delim_whitespace=True, header=None)\n",
        "\n",
        "data_train = dataframe_train.values\n",
        "data_test = dataframe_test.values\n",
        "\n",
        "# because the relationship between Nusselt and input variables follow a power function, we use the log transform to help the ANN training to be more smoothly done:\n",
        "data_train = np.log10(data_train)\n",
        "data_test = np.log10(data_test)\n",
        "\n",
        "# split the dataset into train and validation\n",
        "data_train, data_val = train_test_split(data_train, test_size=0.15, random_state=rnd_seed)\n",
        "\n",
        "# separate the input and output variables:\n",
        "X_train = data_train[:,0:2].reshape(-1, 2) # (Rayleigh, Prandtl)\n",
        "X_val = data_val[:,0:2].reshape(-1, 2) # (Rayleigh, Prandtl)\n",
        "Y_train = data_train[:,2].reshape(-1, 1)   # Nusselt\n",
        "Y_val = data_val[:,2].reshape(-1, 1)   # Nusselt\n",
        "X_test = data_test[:,0:2].reshape(-1, 2) # (Rayleigh, Prandtl)\n",
        "Y_test = data_test[:,2].reshape(-1, 1)   # Nusselt\n",
        "\n",
        "# Compile model\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(4, input_dim=2, kernel_initializer='normal', activation='tanh'))\n",
        "    for i in range(hp.Int('hidden_layers_count', 1, 5, default=2)):\n",
        "        model.add(Dense(hp.Choice('hidden_size', values=[4, 8, 16, 32], default=16), kernel_initializer='normal', activation='tanh'))\n",
        "    model.add(Dense(1, kernel_initializer='normal'))\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(\n",
        "            hp.Float('learning_rate', min_value=5e-4, max_value=1e-3, sampling='LOG', default=5e-4)),        \n",
        "        loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
        "    return model\n",
        "\n",
        "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
        "  def on_train_end(*args, **kwargs):\n",
        "    IPython.display.clear_output(wait = True)\n",
        "\n",
        "# tune model\n",
        "tuner_1 = kt.BayesianOptimization(\n",
        "    build_model,\n",
        "    objective='val_loss',\n",
        "    max_trials=1000,\n",
        "    num_initial_points=2,\n",
        "    directory=dir_opt,\n",
        "    project_name=dir_prj)\n",
        "\n",
        "tuner_2 = kt.Hyperband(\n",
        "    build_model,\n",
        "    objective='val_loss',\n",
        "    factor=2,\n",
        "    max_epochs=1000,\n",
        "    hyperband_iterations=10,\n",
        "    directory=dir_opt,\n",
        "    project_name=dir_prj)\n",
        "\n",
        "tuner = tuner_2 if hyperbandit else tuner_1\n",
        "tuner.search(X_train, Y_train, validation_data = (X_val, Y_val), callbacks=[ClearTrainingOutput(), tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=100)], verbose=0)\n",
        "\n",
        "sys.stdout = open(log_dir, \"w\")\n",
        "best_model = tuner.get_best_models(1)[0]\n",
        "best_hyperparameters = tuner.get_best_hyperparameters(1)[0]\n",
        "best_model.summary()\n",
        "best_model.save(output_dir)\n",
        "result = best_model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('--- test loss:' + str(result))\n",
        "tuner.results_summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-0f595bb06c9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkerastuner\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mkt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kerastuner'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rq2fp6dc8-nX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}